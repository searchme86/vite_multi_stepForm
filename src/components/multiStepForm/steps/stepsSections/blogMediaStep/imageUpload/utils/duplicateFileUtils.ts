// ğŸ“ imageUpload/utils/duplicateFileUtils.ts

import { createLogger } from './loggerUtils';
import type { DuplicateFileResult } from '../types/imageUploadTypes';

const logger = createLogger('DUPLICATE_UTILS');

// ğŸ”‘ íŒŒì¼ ì‹ë³„ì ì¸í„°í˜ì´ìŠ¤ (íŒŒì¼ëª… + í¬ê¸° + ìˆ˜ì •ì¼ ì¡°í•©)
interface FileIdentifier {
  readonly name: string;
  readonly size: number;
  readonly lastModified: number;
  readonly type: string;
}

// ğŸ”‘ íŒŒì¼ í•´ì‹œ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”ìš©)
interface FileHashCache {
  readonly [key: string]: string;
}

// ğŸ”‘ ì „ì—­ í•´ì‹œ ìºì‹œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
const globalFileHashCache: FileHashCache = {};

function validateSingleFile(file: File): boolean {
  try {
    const hasName =
      file?.name && typeof file.name === 'string' && file.name.length > 0;
    const hasSize = file && typeof file.size === 'number' && file.size >= 0;
    const hasLastModified =
      file && typeof file.lastModified === 'number' && file.lastModified > 0;
    const hasType = file && typeof file.type === 'string';

    return Boolean(hasName && hasSize && hasLastModified && hasType);
  } catch {
    return false;
  }
}

function validateFileArray(files: File[]): boolean {
  try {
    return Array.isArray(files) && files.length >= 0;
  } catch {
    return false;
  }
}

function validateStringArray(strings: string[]): boolean {
  try {
    return (
      Array.isArray(strings) &&
      strings.every((str) => typeof str === 'string' && str.length > 0)
    );
  } catch {
    return false;
  }
}

// ğŸ”‘ íŒŒì¼ ê³ ìœ  ì‹ë³„ì ìƒì„± (íŒŒì¼ëª… + í¬ê¸° + ìˆ˜ì •ì¼ + íƒ€ì…)
const createFileIdentifier = (file: File): FileIdentifier => {
  const { name, size, lastModified, type } = file;

  return {
    name: name || 'unknown',
    size: size || 0,
    lastModified: lastModified || 0,
    type: type || 'unknown',
  };
};

// ğŸ”‘ íŒŒì¼ ì‹ë³„ìë¥¼ ë¬¸ìì—´ í‚¤ë¡œ ë³€í™˜
const fileIdentifierToKey = (identifier: FileIdentifier): string => {
  const { name, size, lastModified, type } = identifier;
  return `${name}|${size}|${lastModified}|${type}`;
};

// ğŸ”‘ íŒŒì¼ ê°ì²´ë¥¼ ê³ ìœ  í‚¤ë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¤‘ë³µ ì²´í¬ìš©)
const createFileKey = (file: File): string => {
  const identifier = createFileIdentifier(file);
  return fileIdentifierToKey(identifier);
};

// ğŸ”‘ íŒŒì¼ ë‚´ìš© í•´ì‹œ ìƒì„± (ì‹¬í™” ì¤‘ë³µ ì²´í¬ìš©)
const createFileContentHash = async (file: File): Promise<string> => {
  const fileKey = createFileKey(file);

  // ìºì‹œëœ í•´ì‹œê°€ ìˆìœ¼ë©´ ë°˜í™˜
  const cachedHash = Reflect.get(globalFileHashCache, fileKey);
  if (typeof cachedHash === 'string' && cachedHash.length > 0) {
    console.log('ğŸ“‹ [HASH_CACHE] ìºì‹œëœ í•´ì‹œ ì‚¬ìš©:', {
      íŒŒì¼ëª…: file.name,
      ìºì‹œëœí•´ì‹œ: cachedHash.slice(0, 8) + '...',
    });
    return cachedHash;
  }

  try {
    const arrayBuffer = await file.arrayBuffer();
    const hashBuffer = await crypto.subtle.digest('SHA-256', arrayBuffer);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    const hashHex = hashArray
      .map((byte) => byte.toString(16).padStart(2, '0'))
      .join('');

    // ìºì‹œì— ì €ì¥
    const mutableCache = globalFileHashCache;
    Reflect.set(mutableCache, fileKey, hashHex);

    console.log('ğŸ” [HASH_GENERATE] ìƒˆ íŒŒì¼ í•´ì‹œ ìƒì„±:', {
      íŒŒì¼ëª…: file.name,
      íŒŒì¼í¬ê¸°: file.size,
      ìƒì„±ëœí•´ì‹œ: hashHex.slice(0, 8) + '...',
    });

    return hashHex;
  } catch (hashError) {
    logger.error('íŒŒì¼ í•´ì‹œ ìƒì„± ì‹¤íŒ¨', {
      fileName: file.name,
      error: hashError,
    });

    // í•´ì‹œ ìƒì„± ì‹¤íŒ¨ ì‹œ fallback í‚¤ ë°˜í™˜
    return `fallback-${fileKey}`;
  }
};

// ğŸ”‘ ê¸°ë³¸ ì¤‘ë³µ ì²´í¬ (íŒŒì¼ ì‹ë³„ì ê¸°ë°˜)
const checkBasicDuplicate = (
  targetFile: File,
  existingFileNames: string[],
  processingFileNames: string[]
): boolean => {
  const { name: targetFileName } = targetFile;

  // 1ì°¨: íŒŒì¼ëª… ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
  const isDuplicateInExisting = existingFileNames.includes(targetFileName);
  const isDuplicateInProcessing = processingFileNames.includes(targetFileName);

  const hasBasicDuplicate = isDuplicateInExisting || isDuplicateInProcessing;

  console.log('ğŸ” [BASIC_CHECK] ê¸°ë³¸ ì¤‘ë³µ ì²´í¬:', {
    íŒŒì¼ëª…: targetFileName,
    ê¸°ì¡´íŒŒì¼ì¤‘ë³µ: isDuplicateInExisting,
    ì²˜ë¦¬ì¤‘íŒŒì¼ì¤‘ë³µ: isDuplicateInProcessing,
    ê¸°ë³¸ì¤‘ë³µì—¬ë¶€: hasBasicDuplicate,
  });

  return hasBasicDuplicate;
};

// ğŸ”‘ ê³ ê¸‰ ì¤‘ë³µ ì²´í¬ (íŒŒì¼ ê°ì²´ ë¹„êµ)
const checkAdvancedDuplicate = (
  targetFile: File,
  comparisonFiles: File[]
): boolean => {
  if (comparisonFiles.length === 0) {
    return false;
  }

  const targetIdentifier = createFileIdentifier(targetFile);
  const targetKey = fileIdentifierToKey(targetIdentifier);

  for (let fileIndex = 0; fileIndex < comparisonFiles.length; fileIndex++) {
    const comparisonFile = comparisonFiles[fileIndex];

    if (!validateSingleFile(comparisonFile)) {
      continue;
    }

    const comparisonIdentifier = createFileIdentifier(comparisonFile);
    const comparisonKey = fileIdentifierToKey(comparisonIdentifier);

    const isIdenticalFile = targetKey === comparisonKey;

    if (isIdenticalFile) {
      console.log('ğŸ” [ADVANCED_CHECK] ê³ ê¸‰ ì¤‘ë³µ ë°œê²¬:', {
        íƒ€ê²ŸíŒŒì¼: targetIdentifier.name,
        ë¹„êµíŒŒì¼: comparisonIdentifier.name,
        íƒ€ê²Ÿí‚¤: targetKey,
        ë¹„êµí‚¤: comparisonKey,
        ë™ì¼íŒŒì¼: true,
      });
      return true;
    }
  }

  console.log('ğŸ” [ADVANCED_CHECK] ê³ ê¸‰ ì¤‘ë³µ ì—†ìŒ:', {
    íƒ€ê²ŸíŒŒì¼: targetIdentifier.name,
    ë¹„êµíŒŒì¼ê°œìˆ˜: comparisonFiles.length,
    íƒ€ê²Ÿí‚¤: targetKey,
  });

  return false;
};

// ğŸ”‘ íŒŒì¼ ë°°ì¹˜ ë‚´ ì¤‘ë³µ ì²´í¬
const checkBatchDuplicates = (files: File[]): File[] => {
  if (files.length <= 1) {
    return files;
  }

  const uniqueFiles: File[] = [];
  const seenKeys = new Set<string>();

  for (let fileIndex = 0; fileIndex < files.length; fileIndex++) {
    const currentFile = files[fileIndex];

    if (!validateSingleFile(currentFile)) {
      logger.warn('ë°°ì¹˜ ë‚´ ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ê±´ë„ˆëœ€', {
        fileIndex,
        fileName: currentFile?.name || 'unknown',
      });
      continue;
    }

    const fileKey = createFileKey(currentFile);
    const isAlreadySeen = seenKeys.has(fileKey);

    if (isAlreadySeen) {
      console.log('ğŸš« [BATCH_CHECK] ë°°ì¹˜ ë‚´ ì¤‘ë³µ íŒŒì¼ ì œì™¸:', {
        íŒŒì¼ëª…: currentFile.name,
        íŒŒì¼í‚¤: fileKey,
        ì¸ë±ìŠ¤: fileIndex,
      });
    } else {
      seenKeys.add(fileKey);
      uniqueFiles.push(currentFile);
      console.log('âœ… [BATCH_CHECK] ë°°ì¹˜ ë‚´ ê³ ìœ  íŒŒì¼ ì¶”ê°€:', {
        íŒŒì¼ëª…: currentFile.name,
        íŒŒì¼í‚¤: fileKey,
        ì¸ë±ìŠ¤: fileIndex,
      });
    }
  }

  console.log('ğŸ“Š [BATCH_CHECK] ë°°ì¹˜ ë‚´ ì¤‘ë³µ ì œê±° ì™„ë£Œ:', {
    ì›ë³¸íŒŒì¼ê°œìˆ˜: files.length,
    ê³ ìœ íŒŒì¼ê°œìˆ˜: uniqueFiles.length,
    ì œê±°ëœì¤‘ë³µê°œìˆ˜: files.length - uniqueFiles.length,
  });

  return uniqueFiles;
};

// ğŸ¯ í•µì‹¬: ê°•í™”ëœ ì¤‘ë³µ íŒŒì¼ í•„í„°ë§ (ë‹¤ë‹¨ê³„ ê²€ì¦)
export const filterDuplicateFilesWithProcessing = (
  files: File[],
  existingFileNames: string[],
  processingFileNames: string[] = []
): DuplicateFileResult => {
  if (!validateFileArray(files)) {
    logger.error('ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ë°°ì—´', { hasFiles: Boolean(files) });
    return { uniqueFiles: [], duplicateFiles: [] };
  }

  if (!validateStringArray(existingFileNames)) {
    logger.error('ìœ íš¨í•˜ì§€ ì•Šì€ ê¸°ì¡´ íŒŒì¼ëª… ë°°ì—´');
    return { uniqueFiles: files.slice(), duplicateFiles: [] };
  }

  if (
    !validateStringArray(processingFileNames) &&
    processingFileNames.length > 0
  ) {
    logger.warn('ìœ íš¨í•˜ì§€ ì•Šì€ ì²˜ë¦¬ ì¤‘ íŒŒì¼ëª… ë°°ì—´ - ë¬´ì‹œí•˜ê³  ì§„í–‰');
  }

  const safeProcessingFileNames = validateStringArray(processingFileNames)
    ? processingFileNames
    : [];

  console.log('ğŸ”§ [ENHANCED_DUPLICATE] ê°•í™”ëœ ì¤‘ë³µ ì²´í¬ ì‹œì‘:', {
    ì…ë ¥íŒŒì¼ê°œìˆ˜: files.length,
    ê¸°ì¡´íŒŒì¼ê°œìˆ˜: existingFileNames.length,
    ì²˜ë¦¬ì¤‘íŒŒì¼ê°œìˆ˜: safeProcessingFileNames.length,
    enhancedDuplicateCheck: true,
    timestamp: new Date().toLocaleTimeString(),
  });

  // 1ë‹¨ê³„: ë°°ì¹˜ ë‚´ ì¤‘ë³µ ì œê±° (íŒŒì¼ ê°ì²´ ê¸°ë°˜)
  const batchUniqueFiles = checkBatchDuplicates(files);

  console.log('ğŸ“‹ [ENHANCED_DUPLICATE] 1ë‹¨ê³„ ë°°ì¹˜ ì¤‘ë³µ ì œê±°:', {
    ì²˜ë¦¬ì „íŒŒì¼ê°œìˆ˜: files.length,
    ì²˜ë¦¬í›„íŒŒì¼ê°œìˆ˜: batchUniqueFiles.length,
    ë°°ì¹˜ë‚´ì¤‘ë³µì œê±°ê°œìˆ˜: files.length - batchUniqueFiles.length,
  });

  // 2ë‹¨ê³„: ê¸°ì¡´ íŒŒì¼ê³¼ì˜ ì¤‘ë³µ ì²´í¬ (íŒŒì¼ëª… ê¸°ë°˜)
  const uniqueFiles: File[] = [];
  const duplicateFiles: File[] = [];

  for (let fileIndex = 0; fileIndex < batchUniqueFiles.length; fileIndex++) {
    const currentFile = batchUniqueFiles[fileIndex];

    if (!validateSingleFile(currentFile)) {
      logger.warn('ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ê±´ë„ˆëœ€', {
        fileIndex,
        fileName: currentFile?.name || 'unknown',
      });
      continue;
    }

    // 2-1: ê¸°ë³¸ ì¤‘ë³µ ì²´í¬ (íŒŒì¼ëª… ê¸°ë°˜)
    const hasBasicDuplicate = checkBasicDuplicate(
      currentFile,
      existingFileNames,
      safeProcessingFileNames
    );

    if (hasBasicDuplicate) {
      duplicateFiles.push(currentFile);
      console.log('ğŸš« [ENHANCED_DUPLICATE] 2ë‹¨ê³„ ê¸°ë³¸ ì¤‘ë³µ ë°œê²¬:', {
        íŒŒì¼ëª…: currentFile.name,
        ì¤‘ë³µíƒ€ì…: 'íŒŒì¼ëª…ê¸°ë°˜',
      });
      continue;
    }

    // 2-2: í†µê³¼ëœ íŒŒì¼ì€ ê³ ìœ  íŒŒì¼ë¡œ ë¶„ë¥˜
    uniqueFiles.push(currentFile);
    console.log('âœ… [ENHANCED_DUPLICATE] 2ë‹¨ê³„ ê³ ìœ  íŒŒì¼ í™•ì¸:', {
      íŒŒì¼ëª…: currentFile.name,
      íŒŒì¼í¬ê¸°: currentFile.size,
      íŒŒì¼íƒ€ì…: currentFile.type,
    });
  }

  const finalResult: DuplicateFileResult = { uniqueFiles, duplicateFiles };

  logger.info('ê°•í™”ëœ ì¤‘ë³µ íŒŒì¼ í•„í„°ë§ ì™„ë£Œ', {
    ì „ì²´ì…ë ¥íŒŒì¼: files.length,
    ë°°ì¹˜ë‚´ê³ ìœ íŒŒì¼: batchUniqueFiles.length,
    ìµœì¢…ê³ ìœ íŒŒì¼: uniqueFiles.length,
    ìµœì¢…ì¤‘ë³µíŒŒì¼: duplicateFiles.length,
    ê³ ìœ íŒŒì¼ëª…ë“¤: uniqueFiles.map((file) => file.name),
    ì¤‘ë³µíŒŒì¼ëª…ë“¤: duplicateFiles.map((file) => file.name),
    enhancedProcessing: true,
    multiStageValidation: true,
    timestamp: new Date().toLocaleTimeString(),
  });

  return finalResult;
};

// ğŸ”‘ ì‹¬í™” ì¤‘ë³µ ì²´í¬ (íŒŒì¼ ë‚´ìš© í•´ì‹œ ê¸°ë°˜) - ì˜µì…˜
export const filterDuplicateFilesWithContentHash = async (
  files: File[],
  existingFiles: File[] = []
): Promise<DuplicateFileResult> => {
  if (!validateFileArray(files)) {
    logger.error('ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ë°°ì—´');
    return { uniqueFiles: [], duplicateFiles: [] };
  }

  console.log('ğŸ” [CONTENT_HASH] ë‚´ìš© í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ ì‹œì‘:', {
    ì…ë ¥íŒŒì¼ê°œìˆ˜: files.length,
    ê¸°ì¡´íŒŒì¼ê°œìˆ˜: existingFiles.length,
    contentHashCheck: true,
  });

  const uniqueFiles: File[] = [];
  const duplicateFiles: File[] = [];
  const processedHashes = new Set<string>();

  // ê¸°ì¡´ íŒŒì¼ë“¤ì˜ í•´ì‹œ ìƒì„±
  const existingHashes = new Set<string>();
  for (const existingFile of existingFiles) {
    if (validateSingleFile(existingFile)) {
      try {
        const existingHash = await createFileContentHash(existingFile);
        existingHashes.add(existingHash);
      } catch (hashError) {
        logger.warn('ê¸°ì¡´ íŒŒì¼ í•´ì‹œ ìƒì„± ì‹¤íŒ¨', {
          fileName: existingFile.name,
          error: hashError,
        });
      }
    }
  }

  // ìƒˆ íŒŒì¼ë“¤ ì²˜ë¦¬
  for (const currentFile of files) {
    if (!validateSingleFile(currentFile)) {
      continue;
    }

    try {
      const currentHash = await createFileContentHash(currentFile);

      // ê¸°ì¡´ íŒŒì¼ê³¼ ì¤‘ë³µ ì²´í¬
      const isDuplicateWithExisting = existingHashes.has(currentHash);

      // í˜„ì¬ ë°°ì¹˜ ë‚´ ì¤‘ë³µ ì²´í¬
      const isDuplicateInBatch = processedHashes.has(currentHash);

      const isDuplicate = isDuplicateWithExisting || isDuplicateInBatch;

      if (isDuplicate) {
        duplicateFiles.push(currentFile);
        console.log('ğŸš« [CONTENT_HASH] ë‚´ìš© ê¸°ë°˜ ì¤‘ë³µ ë°œê²¬:', {
          íŒŒì¼ëª…: currentFile.name,
          í•´ì‹œ: currentHash.slice(0, 8) + '...',
          ê¸°ì¡´íŒŒì¼ì¤‘ë³µ: isDuplicateWithExisting,
          ë°°ì¹˜ë‚´ì¤‘ë³µ: isDuplicateInBatch,
        });
      } else {
        uniqueFiles.push(currentFile);
        processedHashes.add(currentHash);
        console.log('âœ… [CONTENT_HASH] ë‚´ìš© ê¸°ë°˜ ê³ ìœ  íŒŒì¼:', {
          íŒŒì¼ëª…: currentFile.name,
          í•´ì‹œ: currentHash.slice(0, 8) + '...',
        });
      }
    } catch (hashError) {
      logger.error('íŒŒì¼ í•´ì‹œ ì²˜ë¦¬ ì‹¤íŒ¨', {
        fileName: currentFile.name,
        error: hashError,
      });

      // í•´ì‹œ ì‹¤íŒ¨ ì‹œ ê³ ìœ  íŒŒì¼ë¡œ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©í–¥)
      uniqueFiles.push(currentFile);
    }
  }

  console.log('ğŸ” [CONTENT_HASH] ë‚´ìš© í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ ì™„ë£Œ:', {
    ê³ ìœ íŒŒì¼ê°œìˆ˜: uniqueFiles.length,
    ì¤‘ë³µíŒŒì¼ê°œìˆ˜: duplicateFiles.length,
    ì²˜ë¦¬ëœí•´ì‹œê°œìˆ˜: processedHashes.size,
  });

  return { uniqueFiles, duplicateFiles };
};

// ğŸ”§ ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
export const checkDuplicateFile = (
  newFile: File,
  existingFileNames: string[]
): boolean => {
  if (!validateSingleFile(newFile)) {
    logger.error('ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ì…ë ¥');
    return false;
  }

  if (!validateStringArray(existingFileNames)) {
    logger.error('ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ëª… ë°°ì—´');
    return false;
  }

  const { name: fileName } = newFile;
  const isDuplicate = existingFileNames.includes(fileName);

  logger.debug('ì¤‘ë³µ íŒŒì¼ ì²´í¬', {
    fileName,
    isDuplicate,
    existingFileNamesCount: existingFileNames.length,
  });

  return isDuplicate;
};

export const filterDuplicateFiles = (
  files: File[],
  existingFileNames: string[]
): DuplicateFileResult => {
  return filterDuplicateFilesWithProcessing(files, existingFileNames, []);
};

export const getDuplicateFileCount = (
  files: File[],
  existingFileNames: string[]
): number => {
  if (!validateFileArray(files)) {
    return 0;
  }

  const filterResult = filterDuplicateFiles(files, existingFileNames);
  return filterResult.duplicateFiles.length;
};

export const getUniqueFileNames = (files: File[]): string[] => {
  if (!validateFileArray(files) || files.length === 0) {
    return [];
  }

  const validFiles = files.filter(validateSingleFile);
  const allFileNames = validFiles.map((file) => file.name);
  const uniqueFileNames: string[] = [];

  for (let i = 0; i < allFileNames.length; i++) {
    const fileName = allFileNames[i];
    if (!uniqueFileNames.includes(fileName)) {
      uniqueFileNames.push(fileName);
    }
  }

  return uniqueFileNames;
};

// ğŸ”‘ ì¶”ê°€ ìœ í‹¸ë¦¬í‹°: íŒŒì¼ í‚¤ ìƒì„± (ì™¸ë¶€ ì‚¬ìš©ìš©)
export const createFileUniqueKey = (file: File): string => {
  if (!validateSingleFile(file)) {
    return 'invalid-file';
  }

  return createFileKey(file);
};

// ğŸ”‘ ì¶”ê°€ ìœ í‹¸ë¦¬í‹°: í•´ì‹œ ìºì‹œ ê´€ë¦¬
export const clearFileHashCache = (): void => {
  const mutableCache = globalFileHashCache;
  const cacheKeys = Object.keys(mutableCache);

  cacheKeys.forEach((key) => {
    Reflect.deleteProperty(mutableCache, key);
  });

  console.log('ğŸ—‘ï¸ [CACHE_CLEAR] íŒŒì¼ í•´ì‹œ ìºì‹œ ì´ˆê¸°í™”:', {
    ì •ë¦¬ëœí‚¤ê°œìˆ˜: cacheKeys.length,
    timestamp: new Date().toLocaleTimeString(),
  });
};

export const getFileHashCacheSize = (): number => {
  return Object.keys(globalFileHashCache).length;
};
